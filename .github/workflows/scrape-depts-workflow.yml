name: Scrape Depts
on:
  schedule:
    # For summer/fall registration
    - cron: '0 0 23 3 *' # 3/23 at 00:00 every year
    - cron: '0 0 30 3 *' # 3/30 at 00:00 every year
    # For spring registration
    - cron: '0 0 16 11 *' # 10/16 at 00:00 every year
    - cron: '0 0 4 11 *' # 11/4 at 00:00 every year

jobs:
  scrape-depts:
    name: 'Scrape Depts'
    runs-on: ubuntu-latest
    env:
      GCP_DB_NAME: ${{ secrets.GCP_DB_NAME }}
    steps:
      - uses: actions/checkout@master

      - name: Fill in Postgres credentials
        run: bash fill_credentials.sh ${{ secrets.POSTGRES_USER }} ${{ secrets.POSTGRES_PASS }}

      - name: Fill in Discord credentials
        run: bash fill_discord_credentials.sh ${{ secrets.DISCORD_BOT_TOKEN }} ${{ secrets.DISCORD_SCRAPE_CHANNEL_ID }} ${{ secrets.DISCORD_FEEDBACK_CHANNEL_ID }}

      - name: Initialize Google Cloud SDK
        uses: zxyle/publish-gae-action@master
        with:
          service_account_email: ${{ secrets.GCP_SA_EMAIL }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          project_id: ${{ secrets.PROJECT_ID }}
          gae_config_path: ./autoscheduler/app.yaml

      - name: Initialize GCP Credentials
        run: |
          # This client-secret.json is converted by GCP_SA_KEY
          gcloud auth activate-service-account ${{ secrets.GCP_SA_EMAIL }} --key-file=client-secret.json
          gcloud config set project ${{ secrets.PROJECT_ID }}

      # By default it copies to ./client-secret.json, but we need it in docker/cloud-sql-proxy so its in
      # the cloud-sql-proxy-cred-file's context
      - name: Copy client-secret.json
        run: cp client-secret.json docker/cloud-sql-proxy-cred-file/client-secret.json

      - name: docker-build
        # sudo -E so we can access the GCP_DB_NAME env var 
        run: sudo -E docker-compose up --abort-on-container-exit scrape-depts
